#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <cublas_v2.h>
#include <cmath>
#include <iostream>

#define HIDDEN_SIZE 4096
#define INTERMEDIATE_SIZE 12288
#define USE_FP16 1  // Set to 0 for FP32

#define CHECK_CUDA(call) \
    do { \
        cudaError_t err = call; \
        if (err != cudaSuccess) { \
            std::cerr << "CUDA error at " << __FILE__ << ":" << __LINE__ << " - " \
                    << cudaGetErrorString(err) << std::endl; \
            exit(1); \
        } \
    } while(0)

#define CHECK_CUBLAS(call) \
    do { \
        cublasStatus_t status = call; \
        if (status != CUBLAS_STATUS_SUCCESS) { \
            std::cerr << "cuBLAS error at " << __FILE__ << ":" << __LINE__ << std::endl; \
            exit(1); \
        } \
    } while(0)

// ====================================================================================
// FP16 + Tensor Core Helper
// ====================================================================================

__device__ __forceinline__ float half_to_float(__half h) {
    return __half2float(h);
}

__device__ __forceinline__ __half float_to_half(float f) {
    return __float2half(f);
}

// ====================================================================================
// GELU Activation (using inverse tanh)
// ====================================================================================

__device__ __forceinline__ float gelu(float x) {
    const float k = 0.7978845608f;  // sqrt(2/pi)
    return 0.5f * x * (1.0f + tanhf(k * (x + 0.044715f * x * x * x)));
}


// ====================================================================================
// GEGLU elementwise kernel (FP16 version)
// ====================================================================================

__global__ void geglu_kernel_fp16(
    const __half* __restrict__ U,
    const __half* __restrict__ V,
    __half* __restrict__ Y,
    int n
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= n) return;

    // Convert FP16 to FP32 for GELU computation
    float u = __half2float(U[idx]);
    float v = __half2float(V[idx]);

    float result = gelu(u) * v;
    Y[idx] = __float2half(result);
}


// ====================================================================================
// Fast GEGLU FFN (cuBLAS + tiny kernel) with FP16 + Tensor Cores
// ====================================================================================

void geglu_ffn(
    cublasHandle_t handle,
    const __half* x,    
    const __half* Wu,    
    const __half* Wv,    
    const __half* Wo,    
    __half* U,          
    __half* V,           
    __half* intermediate,
    __half* output,      
    int B
) {
    // Enable TF32 for better Tensor Core performance
    cublasSetMathMode(handle, CUBLAS_TF32_TENSOR_OP_MATH);

    const float alpha = 1.0f;
    const float beta  = 0.0f;

    // Compute U = Wu @ x
    CHECK_CUBLAS(cublasSgemmEx(
        handle,
        CUBLAS_OP_T, CUBLAS_OP_N,
        INTERMEDIATE_SIZE, B, HIDDEN_SIZE,
        &alpha,
        Wu, CUDA_R_16F, HIDDEN_SIZE,
        x,  CUDA_R_16F, HIDDEN_SIZE,
        &beta,
        U,  CUDA_R_16F, INTERMEDIATE_SIZE
    ));

    // Compute V = Wv @ x 
    CHECK_CUBLAS(cublasSgemmEx(
        handle,
        CUBLAS_OP_T, CUBLAS_OP_N,
        INTERMEDIATE_SIZE, B, HIDDEN_SIZE,
        &alpha,
        Wv, CUDA_R_16F, HIDDEN_SIZE,
        x,  CUDA_R_16F, HIDDEN_SIZE,
        &beta,
        V,  CUDA_R_16F, INTERMEDIATE_SIZE
    ));

    // GEGLU: intermediate = gelu(U) * V
    int n = B * INTERMEDIATE_SIZE;
    int threads = 256;
    int blocks = (n + threads - 1) / threads;

    geglu_kernel_fp16<<<blocks, threads>>>(U, V, intermediate, n);
    CHECK_CUDA(cudaGetLastError());

    // Compute output = Wo @ intermediate
    CHECK_CUBLAS(cublasSgemmEx(
        handle,
        CUBLAS_OP_T, CUBLAS_OP_N,
        HIDDEN_SIZE, B, INTERMEDIATE_SIZE,
        &alpha,
        Wo, CUDA_R_16F, INTERMEDIATE_SIZE,
        intermediate, CUDA_R_16F, INTERMEDIATE_SIZE,
        &beta,
        output, CUDA_R_16F, HIDDEN_SIZE
    ));
}
